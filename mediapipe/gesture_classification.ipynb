{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.csvoperations import read_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'model/data/landmarks_data.csv'\n",
    "labels_path = 'model/data/gestures_labels.csv'\n",
    "model_save_path = 'model/gesture_classifier.hdf5'\n",
    "tflite_model_save_path = 'model/gesture_classifier.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "N_FEATURES = 21 * 2\n",
    "RANDOM_STATE = 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(data_path, np.float32, delimiter=',', usecols=list(range(1, N_FEATURES + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataset = np.loadtxt(data_path, np.int32, delimiter=',', usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Open', 1: 'Closed', 2: 'Okay', 3: 'Thumbs up', 4: 'Thumbs down'}\n"
     ]
    }
   ],
   "source": [
    "labels = read_labels(labels_path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples: 10370\n",
      "Number of labels: 10370\n",
      "Number of unique classes: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data samples: {X_dataset.shape[0]}\")\n",
    "print(f\"Number of labels: {Y_dataset.shape[0]}\")\n",
    "real_n_classes = len(set(Y_dataset))\n",
    "print(f\"Number of unique classes: {real_n_classes}\")\n",
    "assert real_n_classes == NUM_CLASSES, f\"Number of unique classess ({real_n_classes}) differs from NUM_CLASSES ({NUM_CLASSES})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                        X_dataset,\n",
    "                                        Y_dataset,\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=RANDOM_STATE,\n",
    "                                        stratify=Y_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(N_FEATURES,)),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                860       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1125 (4.39 KB)\n",
      "Trainable params: 1125 (4.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add model saving callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoing_callback = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path,\n",
    "    save_weights_only=False,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 15:41:41.473367: I external/local_xla/xla/service/service.cc:168] XLA service 0x5639590fea70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-19 15:41:41.473422: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2024-05-19 15:41:41.537804: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716126101.659011   70636 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 5s 9ms/step - loss: 1.2858 - accuracy: 0.5259 - val_loss: 1.0249 - val_accuracy: 0.6996\n",
      "Epoch 2/50\n",
      " 17/260 [>.............................] - ETA: 1s - loss: 1.0730 - accuracy: 0.6360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acodered/.pyenv/versions/3.10.0/envs/gestures/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 2s 9ms/step - loss: 0.9426 - accuracy: 0.6604 - val_loss: 0.7178 - val_accuracy: 0.7917\n",
      "Epoch 3/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.7540 - accuracy: 0.7097 - val_loss: 0.5588 - val_accuracy: 0.8534\n",
      "Epoch 4/50\n",
      "260/260 [==============================] - 2s 9ms/step - loss: 0.6581 - accuracy: 0.7583 - val_loss: 0.4500 - val_accuracy: 0.8751\n",
      "Epoch 5/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.5603 - accuracy: 0.7942 - val_loss: 0.3735 - val_accuracy: 0.8954\n",
      "Epoch 6/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.4973 - accuracy: 0.8204 - val_loss: 0.3041 - val_accuracy: 0.9209\n",
      "Epoch 7/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.4329 - accuracy: 0.8479 - val_loss: 0.2405 - val_accuracy: 0.9349\n",
      "Epoch 8/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.3921 - accuracy: 0.8567 - val_loss: 0.2157 - val_accuracy: 0.9368\n",
      "Epoch 9/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.3485 - accuracy: 0.8732 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
      "Epoch 10/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.3218 - accuracy: 0.8834 - val_loss: 0.1690 - val_accuracy: 0.9508\n",
      "Epoch 11/50\n",
      "260/260 [==============================] - 2s 9ms/step - loss: 0.3032 - accuracy: 0.8939 - val_loss: 0.1671 - val_accuracy: 0.9542\n",
      "Epoch 12/50\n",
      "260/260 [==============================] - 2s 9ms/step - loss: 0.2829 - accuracy: 0.8981 - val_loss: 0.1438 - val_accuracy: 0.9581\n",
      "Epoch 13/50\n",
      "260/260 [==============================] - 2s 9ms/step - loss: 0.2741 - accuracy: 0.9041 - val_loss: 0.1433 - val_accuracy: 0.9614\n",
      "Epoch 14/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.2563 - accuracy: 0.9066 - val_loss: 0.1419 - val_accuracy: 0.9662\n",
      "Epoch 15/50\n",
      "260/260 [==============================] - 2s 9ms/step - loss: 0.2425 - accuracy: 0.9168 - val_loss: 0.1371 - val_accuracy: 0.9624\n",
      "Epoch 16/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.2382 - accuracy: 0.9166 - val_loss: 0.1299 - val_accuracy: 0.9643\n",
      "Epoch 17/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.2370 - accuracy: 0.9121 - val_loss: 0.1217 - val_accuracy: 0.9653\n",
      "Epoch 18/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.2314 - accuracy: 0.9163 - val_loss: 0.1243 - val_accuracy: 0.9648\n",
      "Epoch 19/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.2164 - accuracy: 0.9218 - val_loss: 0.1165 - val_accuracy: 0.9648\n",
      "Epoch 20/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.2150 - accuracy: 0.9236 - val_loss: 0.1122 - val_accuracy: 0.9653\n",
      "Epoch 21/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.2125 - accuracy: 0.9198 - val_loss: 0.1106 - val_accuracy: 0.9677\n",
      "Epoch 22/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1993 - accuracy: 0.9276 - val_loss: 0.1156 - val_accuracy: 0.9682\n",
      "Epoch 23/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1992 - accuracy: 0.9297 - val_loss: 0.1143 - val_accuracy: 0.9691\n",
      "Epoch 24/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1991 - accuracy: 0.9264 - val_loss: 0.1057 - val_accuracy: 0.9682\n",
      "Epoch 25/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1962 - accuracy: 0.9337 - val_loss: 0.1123 - val_accuracy: 0.9658\n",
      "Epoch 26/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1920 - accuracy: 0.9329 - val_loss: 0.1026 - val_accuracy: 0.9658\n",
      "Epoch 27/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1971 - accuracy: 0.9303 - val_loss: 0.1087 - val_accuracy: 0.9701\n",
      "Epoch 28/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1948 - accuracy: 0.9304 - val_loss: 0.1115 - val_accuracy: 0.9643\n",
      "Epoch 29/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1825 - accuracy: 0.9351 - val_loss: 0.1200 - val_accuracy: 0.9629\n",
      "Epoch 30/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1806 - accuracy: 0.9365 - val_loss: 0.1025 - val_accuracy: 0.9696\n",
      "Epoch 31/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1830 - accuracy: 0.9355 - val_loss: 0.1125 - val_accuracy: 0.9672\n",
      "Epoch 32/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1832 - accuracy: 0.9365 - val_loss: 0.0981 - val_accuracy: 0.9754\n",
      "Epoch 33/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1718 - accuracy: 0.9388 - val_loss: 0.0950 - val_accuracy: 0.9749\n",
      "Epoch 34/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1776 - accuracy: 0.9359 - val_loss: 0.1171 - val_accuracy: 0.9716\n",
      "Epoch 35/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1781 - accuracy: 0.9368 - val_loss: 0.0991 - val_accuracy: 0.9720\n",
      "Epoch 36/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1735 - accuracy: 0.9348 - val_loss: 0.0954 - val_accuracy: 0.9754\n",
      "Epoch 37/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1679 - accuracy: 0.9388 - val_loss: 0.1005 - val_accuracy: 0.9754\n",
      "Epoch 38/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1708 - accuracy: 0.9383 - val_loss: 0.1034 - val_accuracy: 0.9730\n",
      "Epoch 39/50\n",
      "260/260 [==============================] - 2s 7ms/step - loss: 0.1655 - accuracy: 0.9409 - val_loss: 0.1006 - val_accuracy: 0.9720\n",
      "Epoch 40/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1636 - accuracy: 0.9403 - val_loss: 0.0985 - val_accuracy: 0.9740\n",
      "Epoch 41/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1631 - accuracy: 0.9432 - val_loss: 0.0958 - val_accuracy: 0.9730\n",
      "Epoch 42/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1586 - accuracy: 0.9427 - val_loss: 0.0889 - val_accuracy: 0.9764\n",
      "Epoch 43/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1602 - accuracy: 0.9447 - val_loss: 0.1064 - val_accuracy: 0.9687\n",
      "Epoch 44/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1637 - accuracy: 0.9419 - val_loss: 0.0996 - val_accuracy: 0.9730\n",
      "Epoch 45/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1587 - accuracy: 0.9438 - val_loss: 0.0956 - val_accuracy: 0.9711\n",
      "Epoch 46/50\n",
      "260/260 [==============================] - 2s 10ms/step - loss: 0.1541 - accuracy: 0.9458 - val_loss: 0.0857 - val_accuracy: 0.9764\n",
      "Epoch 47/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1609 - accuracy: 0.9430 - val_loss: 0.1043 - val_accuracy: 0.9725\n",
      "Epoch 48/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1552 - accuracy: 0.9442 - val_loss: 0.0862 - val_accuracy: 0.9769\n",
      "Epoch 49/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1561 - accuracy: 0.9452 - val_loss: 0.1005 - val_accuracy: 0.9740\n",
      "Epoch 50/50\n",
      "260/260 [==============================] - 2s 8ms/step - loss: 0.1531 - accuracy: 0.9476 - val_loss: 0.0887 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_test, Y_test), callbacks=[checkpoing_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9778\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "_, _ = model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "[[9.9983525e-01 6.1941535e-11 6.6216926e-05 9.0094409e-13 9.8505356e-05]]\n",
      "0 - Open\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(np.array([X_test[0]]))\n",
    "print(result)\n",
    "print(f\"{np.argmax(result)} - {labels[np.argmax(result)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_yu6ewkd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_yu6ewkd/assets\n",
      "2024-05-19 15:43:39.098999: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-19 15:43:39.099057: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-19 15:43:39.099320: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp_yu6ewkd\n",
      "2024-05-19 15:43:39.100061: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-19 15:43:39.100073: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp_yu6ewkd\n",
      "2024-05-19 15:43:39.102774: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-19 15:43:39.135274: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp_yu6ewkd\n",
      "2024-05-19 15:43:39.144473: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 45154 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(tflite_model_save_path, 'wb') as file:\n",
    "    file.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gestures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
